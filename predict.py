#Predict anime face

import os
import sys
from keras.applications.vgg16 import VGG16
from keras.models import Sequential, Model
from keras.layers import Input, Activation, Dropout, Flatten, Dense
from keras.preprocessing import image
import numpy as np

if len(sys.argv) != 2:
    #print("usage: python predict.py [filename]")
    #sys.exit(1)
	filename = "animeface-character-dataset/thumb/000_hatsune_miku/face_27_136_113.png"
else:
	filename = sys.argv[1]

print('input:', filename)

result_dir = 'results'

img_height, img_width = 160, 160
channels = 3

model.load('animeface.hdf5')

# VGG16
input_tensor = Input(shape=(img_height, img_width, channels))
#vgg16_model = VGG16(include_top=False, weights='imagenet', input_tensor=input_tensor)

# FC
#top_model = Sequential()
#top_model.add(Flatten(input_shape=vgg16_model.output_shape[1:]))
#top_model.add(Dense(256, activation='relu'))
#top_model.add(Dropout(0.5))
#top_model.add(Dense(1, activation='sigmoid'))

# VGG16とFCを接続
#model = Model(input=vgg16_model.input, output=top_model(vgg16_model.output))

# 学習済みの重みをロード
#model.load_weights(os.path.join(result_dir, 'finetuning.h5'))

#model.compile(loss='binary_crossentropy',
#              optimizer='adam',
#              metrics=['accuracy'])
model.summary()

# 画像を読み込んで4次元テンソルへ変換
img = image.load_img(filename, target_size=(img_height, img_width))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)

# 学習時にImageDataGeneratorのrescaleで正規化したので同じ処理が必要！
# これを忘れると結果がおかしくなるので注意
x = x / 255.0

# print(x)
# print(x.shape)

# クラスを予測
# 入力は1枚の画像なので[0]のみ
pred = model.predict(x)[0]
print(pred)

prob = np.max(pred)
cls = pred.argmax()

lines=open('animeface-character-dataset/tools/tag_ja.txt').readlines()
print prob, cls, lines[cls]
